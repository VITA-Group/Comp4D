# Comp4D: LLM-Guided Compositional 4D Scene Generation

Authors: Dejia Xu, Hanwen Liang, Neel P. Bhatt1, Hezhen Hu, Hanxue Liang,
Konstantinos N. Plataniotis, and Zhangyang Wang

[[Project Page]](https://vita-group.github.io/Comp4D/) | [[Video (narrated)]](https://www.youtube.com/watch?v=9q8SV1Xf_Xw) | [[Video (results only)]](https://www.youtube.com/watch?v=gXVoPTGb734) | [[Paper]](https://github.com/VITA-Group/Comp4D/blob/main/Comp4D.pdf) | [[Arxiv]](https://arxiv.org/abs/2403.16993)


![overview](docs/static/media/task.29476c66b38120ba3c46.jpg)

## Overview
As show in figure above, we introduce **Comp**ositional **4D** Scene Generation. Previous work concentrate on object-centric 4D objects. In comparison, our work extends the boundaries to the demanding task of constructing compositional 4D scenes. We integrate GPT-4 to decompose the scene and design proper trajectories, resulting in larger-scale movements and more realistic object interactions.

## Code is coming soon!

## Citation

If you find this repository/work helpful in your research, please consider citing the paper and starring the repo ‚≠ê.

